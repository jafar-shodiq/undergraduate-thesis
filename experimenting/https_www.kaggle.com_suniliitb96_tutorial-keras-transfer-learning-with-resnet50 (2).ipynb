{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"https://www.kaggle.com/suniliitb96/tutorial-keras-transfer-learning-with-resnet50 (2).ipynb","provenance":[],"authorship_tag":"ABX9TyPN18zlceqNILrZLBD/64m6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"goX8lAtDaoWo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"564db9e6-52ad-4b3e-d896-6a6755ab074f","executionInfo":{"status":"ok","timestamp":1583121965063,"user_tz":-420,"elapsed":78156,"user":{"displayName":"Muhammad Jafar Shodiq","photoUrl":"","userId":"01084952841962473482"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7dF45o1CatjJ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gvd2PcVVbElK","colab_type":"code","colab":{}},"source":["# Fixed for our Cats & Dogs classes\n","NUM_CLASSES = 2\n","\n","# Fixed for Cats & Dogs color images\n","CHANNELS = 3\n","\n","IMAGE_RESIZE = 224\n","RESNET50_POOLING_AVERAGE = 'avg'\n","DENSE_LAYER_ACTIVATION = 'softmax'\n","OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n","\n","# Common accuracy metric for all outputs, but can use different metrics for different output\n","LOSS_METRICS = ['accuracy']\n","\n","# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n","NUM_EPOCHS = 10\n","EARLY_STOP_PATIENCE = 3\n","\n","# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n","# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n","STEPS_PER_EPOCH_TRAINING = 10\n","STEPS_PER_EPOCH_VALIDATION = 10\n","\n","# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n","# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n","BATCH_SIZE_TRAINING = 100\n","BATCH_SIZE_VALIDATION = 100\n","\n","# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n","BATCH_SIZE_TESTING = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nHdlfHYbIEj","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras.applications import ResNet50\n","from tensorflow.python.keras.models import Sequential\n","from tensorflow.python.keras.layers import Dense\n","\n","### \n","### Below systax is available with TensorFlow 1.11 onwards but this upgrade is not available for Kaggle kernel yet\n","###\n","#import tensorflow as tf\n","#print(tf.__version__)\n","#import tensorflow as tf\n","#from tf.keras.applications import ResNet50\n","#from tf.keras.models import Sequential"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzjEJNtXbKKE","colab_type":"code","colab":{}},"source":["resnet_weights_path = '/content/drive/My Drive/Dataset/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qNGH0cyObOfm","colab_type":"code","colab":{}},"source":["#Still not talking about our train/test data or any pre-processing.\n","\n","model = Sequential()\n","\n","# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n","model.add(ResNet50(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path))\n","\n","# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n","model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n","\n","# Say not to train first layer (ResNet) model as it is already trained\n","model.layers[0].trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UF4ZsIBobP-L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":218},"outputId":"7c1e098c-c5cb-4622-a0fb-11e39bf66444","executionInfo":{"status":"ok","timestamp":1583122922272,"user_tz":-420,"elapsed":10698,"user":{"displayName":"Muhammad Jafar Shodiq","photoUrl":"","userId":"01084952841962473482"}}},"source":["model.summary()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","resnet50 (Model)             (None, 2048)              23587712  \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 4098      \n","=================================================================\n","Total params: 23,591,810\n","Trainable params: 4,098\n","Non-trainable params: 23,587,712\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F2MDjsbceJlW","colab_type":"code","colab":{}},"source":["from tensorflow.python.keras import optimizers\n","\n","sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n","model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRHE9G5RbUMn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"c5ad56d3-4a96-4b17-deb5-61dec34f718d","executionInfo":{"status":"ok","timestamp":1583122926058,"user_tz":-420,"elapsed":1029,"user":{"displayName":"Muhammad Jafar Shodiq","photoUrl":"","userId":"01084952841962473482"}}},"source":["from keras.applications.resnet50 import preprocess_input\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","image_size = IMAGE_RESIZE\n","\n","# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n","# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n","# Batch Normalization helps in faster convergence\n","data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n","# Both train & valid folders must have NUM_CLASSES sub-folders\n","train_generator = data_generator.flow_from_directory(\n","        '/content/drive/My Drive/Dataset/plantdisease-2classes/train',\n","        target_size=(image_size, image_size),\n","        batch_size=BATCH_SIZE_TRAINING,\n","        class_mode='categorical')\n","\n","validation_generator = data_generator.flow_from_directory(\n","        '/content/drive/My Drive/Dataset/plantdisease-2classes/test',\n","        target_size=(image_size, image_size),\n","        batch_size=BATCH_SIZE_VALIDATION,\n","        class_mode='categorical') "],"execution_count":31,"outputs":[{"output_type":"stream","text":["Found 1600 images belonging to 2 classes.\n","Found 400 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x58MXPMQbWrH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8679ac5c-14a0-4d00-d2d0-7bbfd1e148ac","executionInfo":{"status":"ok","timestamp":1583122927099,"user_tz":-420,"elapsed":594,"user":{"displayName":"Muhammad Jafar Shodiq","photoUrl":"","userId":"01084952841962473482"}}},"source":["# Max number of steps that these generator will have opportunity to process their source content\n","# len(train_generator) should be 'no. of available train images / BATCH_SIZE_TRAINING'\n","# len(valid_generator) should be 'no. of available train images / BATCH_SIZE_VALIDATION'\n","(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(validation_generator))"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 16, 100, 4)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"P_ZdlvGCbmqO","colab_type":"code","colab":{}},"source":["# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n","from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n","cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkjedmHxbokA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"84777616-a08e-4edb-e7b2-837f0c99f3d3","executionInfo":{"status":"ok","timestamp":1583122929578,"user_tz":-420,"elapsed":631,"user":{"displayName":"Muhammad Jafar Shodiq","photoUrl":"","userId":"01084952841962473482"}}},"source":["# Grid Search is an ideal candidate for distributed machine learning\n","# Pseudo code for hyperparameters Grid Search\n","\n","'''\n","from sklearn.grid_search import ParameterGrid\n","param_grid = {'epochs': [5, 10, 15], 'steps_per_epoch' : [10, 20, 50]}\n","\n","grid = ParameterGrid(param_grid)\n","\n","# Accumulate history of all permutations (may be for viewing trend) and keep watching for lowest val_loss as final model\n","for params in grid:\n","    print(params)\n","'''"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfrom sklearn.grid_search import ParameterGrid\\nparam_grid = {'epochs': [5, 10, 15], 'steps_per_epoch' : [10, 20, 50]}\\n\\ngrid = ParameterGrid(param_grid)\\n\\n# Accumulate history of all permutations (may be for viewing trend) and keep watching for lowest val_loss as final model\\nfor params in grid:\\n    print(params)\\n\""]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"ffmpqXvSbp-t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":474},"outputId":"bb55fac1-30e5-4cba-eada-e76565c74d72","executionInfo":{"status":"error","timestamp":1583122950317,"user_tz":-420,"elapsed":19979,"user":{"displayName":"Muhammad Jafar Shodiq","photoUrl":"","userId":"01084952841962473482"}}},"source":["fit_history = model.fit_generator(\n","        train_generator,\n","        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n","        epochs = NUM_EPOCHS,\n","        validation_data=validation_generator,\n","        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n","        callbacks=[cb_checkpointer, cb_early_stopper]\n",")\n","model.load_weights(\"../working/best.hdf5\")"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-3931aa6736b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH_VALIDATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb_checkpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_early_stopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../working/best.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Computed output size would be negative: -227 [input_size: 56, effective_filter_size: 512, stride: 2]\n\t [[{{node resnet50_2/conv3_block1_0_conv/BiasAdd}}]]"]}]},{"cell_type":"code","metadata":{"id":"_QETiFumbrYy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}